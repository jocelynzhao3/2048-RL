{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663eb36c",
   "metadata": {},
   "source": [
    "2048 DQN CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a85d299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/2048/lib/python3.10/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_stream, resource_exists\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # for matrix and numerical operations\n",
    "import random  # for epsilon-greedy random action selection\n",
    "import torch  # PyTorch core library\n",
    "import torch.nn as nn  # for building neural networks\n",
    "import torch.optim as optim  # for optimizer (e.g. Adam)\n",
    "import torch.nn.functional as F  # for activation functions like ReLU\n",
    "from collections import deque  # not used here, but useful for experience buffers\n",
    "import gymnasium as gym  # for interacting with RL environments\n",
    "import gymnasium_2048.envs  # registers the 2048 environment\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4984f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_CNN(nn.Module):\n",
    "    def __init__(self, input_channels=16, output_dim=4):\n",
    "        super().__init__()\n",
    "        # input channels, output channels, kernel_size\n",
    "        self.conv1 = nn.Conv2d(input_channels, 128, kernel_size=(1,2))\n",
    "        self.conv2 = nn.Conv2d(input_channels, 128, kernel_size=(2,1))\n",
    "\n",
    "        self.conv11 = nn.Conv2d(128, 128, kernel_size=(1,2))\n",
    "        self.conv12 = nn.Conv2d(128, 128, kernel_size=(2,1))\n",
    "        self.conv21 = nn.Conv2d(128, 128, kernel_size=(1,2))\n",
    "        self.conv22 = nn.Conv2d(128, 128, kernel_size=(2,1))\n",
    "\n",
    "        self.fc1 = nn.Linear(128*3*4*2+128*3*3*2+128*4*2*2, 256)\n",
    "        self.out = nn.Linear(256, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = F.relu(self.conv2(x))\n",
    "\n",
    "        x11 = F.relu(self.conv11(x1))\n",
    "        x12 = F.relu(self.conv12(x1))\n",
    "        x21 = F.relu(self.conv21(x2))\n",
    "        x22 = F.relu(self.conv22(x2))\n",
    "\n",
    "        x1_flat = x1.flatten(start_dim=1)\n",
    "        x2_flat = x2.flatten(start_dim=1)\n",
    "        x11_flat = x11.flatten(start_dim=1)\n",
    "        x12_flat = x12.flatten(start_dim=1)\n",
    "        x21_flat = x21.flatten(start_dim=1)\n",
    "        x22_flat = x22.flatten(start_dim=1)\n",
    "\n",
    "        x = torch.cat([x1_flat, x2_flat, x11_flat, x12_flat, x21_flat, x22_flat], dim=1)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca29442",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritizedReplayBuffer:\n",
    "    def __init__(self, capacity, alpha=0.7):\n",
    "        self.capacity = capacity\n",
    "        self.buffer = []  # stores experiences (s, a, r, s', done)\n",
    "        self.pos = 0\n",
    "        self.priorities = np.zeros((capacity,), dtype=np.float32)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def add(self, transition, td_error):\n",
    "        max_prio = max(self.priorities.max(), td_error + 1e-6)\n",
    "        if len(self.buffer) < self.capacity:\n",
    "            self.buffer.append(transition)\n",
    "        else:\n",
    "            self.buffer[self.pos] = transition\n",
    "        self.priorities[self.pos] = max_prio\n",
    "        self.pos = (self.pos + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size, beta=0.4):\n",
    "        prios = self.priorities if len(self.buffer) == self.capacity else self.priorities[:self.pos]\n",
    "        probs = prios ** self.alpha\n",
    "        probs /= probs.sum()\n",
    "\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, p=probs)\n",
    "        samples = [self.buffer[i] for i in indices]\n",
    "\n",
    "        total = len(self.buffer)\n",
    "        weights = (total * probs[indices]) ** (-beta)\n",
    "        weights /= weights.max()\n",
    "        weights = torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "        return samples, weights, indices\n",
    "\n",
    "    def update_priorities(self, indices, td_errors):\n",
    "        for idx, err in zip(indices, td_errors):\n",
    "            self.priorities[idx] = abs(err.item()) + 1e-6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d71977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "def find_high_tile(state):\n",
    "    state = np.argmax(state, axis=2)\n",
    "    state = 2 ** state * (state > 0)\n",
    "    return np.max(state)\n",
    "\n",
    "def preprocess(state): # 4, 4, 16\n",
    "    state = torch.tensor(state)\n",
    "    transposed = state.permute(2, 0, 1)   # (16, 4, 4)\n",
    "    return transposed\n",
    "\n",
    "def reward_shaping(state):\n",
    "    state = np.argmax(state, axis=2)\n",
    "    grid = 2 ** state * (state > 0)\n",
    "    empty = np.count_nonzero(grid == 0)\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823599e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 000 | High tile: 64 | Steps: 98 | Epsilon: 0.9920\n",
      "Episode 050 | High tile: 128 | Steps: 208 | Epsilon: 0.6639\n",
      "Episode 100 | High tile: 128 | Steps: 137 | Epsilon: 0.4443\n",
      "Episode 150 | High tile: 256 | Steps: 358 | Epsilon: 0.2973\n",
      "Episode 200 | High tile: 256 | Steps: 221 | Epsilon: 0.1990\n",
      "Episode 250 | High tile: 512 | Steps: 430 | Epsilon: 0.1332\n",
      "Episode 300 | High tile: 512 | Steps: 472 | Epsilon: 0.0891\n",
      "Episode 350 | High tile: 512 | Steps: 458 | Epsilon: 0.0596\n",
      "Episode 400 | High tile: 512 | Steps: 428 | Epsilon: 0.0399\n",
      "Episode 450 | High tile: 512 | Steps: 598 | Epsilon: 0.0267\n",
      "Episode 500 | High tile: 256 | Steps: 307 | Epsilon: 0.0179\n",
      "Episode 550 | High tile: 256 | Steps: 352 | Epsilon: 0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/rl2048/lib/python3.12/site-packages/gymnasium_2048/envs/twenty_forty_eight.py:158: RuntimeWarning: overflow encountered in scalar add\n",
      "  score += 2 ** (board[row, col] + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 600 | High tile: 256 | Steps: 249 | Epsilon: 0.0080\n",
      "Episode 650 | High tile: 128 | Steps: 166 | Epsilon: 0.0054\n",
      "Episode 700 | High tile: 512 | Steps: 611 | Epsilon: 0.0036\n",
      "Episode 750 | High tile: 128 | Steps: 179 | Epsilon: 0.0024\n",
      "Episode 800 | High tile: 256 | Steps: 398 | Epsilon: 0.0016\n",
      "Episode 850 | High tile: 256 | Steps: 380 | Epsilon: 0.0011\n",
      "Episode 900 | High tile: 512 | Steps: 408 | Epsilon: 0.0007\n",
      "Episode 950 | High tile: 128 | Steps: 164 | Epsilon: 0.0005\n",
      "Episode 1000 | High tile: 256 | Steps: 241 | Epsilon: 0.0005\n",
      "Episode 1050 | High tile: 512 | Steps: 520 | Epsilon: 0.0005\n",
      "Episode 1100 | High tile: 512 | Steps: 415 | Epsilon: 0.0005\n",
      "Episode 1150 | High tile: 128 | Steps: 169 | Epsilon: 0.0005\n",
      "Episode 1200 | High tile: 512 | Steps: 555 | Epsilon: 0.0005\n",
      "Episode 1250 | High tile: 256 | Steps: 246 | Epsilon: 0.0005\n",
      "Episode 1300 | High tile: 256 | Steps: 287 | Epsilon: 0.0005\n",
      "Episode 1350 | High tile: 512 | Steps: 422 | Epsilon: 0.0005\n",
      "Episode 1400 | High tile: 512 | Steps: 570 | Epsilon: 0.0005\n",
      "Episode 1450 | High tile: 512 | Steps: 599 | Epsilon: 0.0005\n",
      "Episode 1500 | High tile: 512 | Steps: 576 | Epsilon: 0.0005\n",
      "Episode 1550 | High tile: 512 | Steps: 409 | Epsilon: 0.0005\n",
      "Episode 1600 | High tile: 512 | Steps: 352 | Epsilon: 0.0005\n",
      "Episode 1650 | High tile: 1024 | Steps: 630 | Epsilon: 0.0005\n",
      "Episode 1700 | High tile: 512 | Steps: 422 | Epsilon: 0.0005\n",
      "Episode 1750 | High tile: 256 | Steps: 309 | Epsilon: 0.0005\n",
      "Episode 1800 | High tile: 1024 | Steps: 772 | Epsilon: 0.0005\n",
      "Episode 1850 | High tile: 256 | Steps: 316 | Epsilon: 0.0005\n",
      "Episode 1900 | High tile: 256 | Steps: 263 | Epsilon: 0.0005\n",
      "Episode 1950 | High tile: 512 | Steps: 527 | Epsilon: 0.0005\n",
      "Episode 2000 | High tile: 512 | Steps: 407 | Epsilon: 0.0005\n",
      "Episode 2050 | High tile: 256 | Steps: 298 | Epsilon: 0.0005\n",
      "Episode 2100 | High tile: 512 | Steps: 492 | Epsilon: 0.0005\n",
      "Episode 2150 | High tile: 512 | Steps: 503 | Epsilon: 0.0005\n",
      "Episode 2200 | High tile: 256 | Steps: 325 | Epsilon: 0.0005\n",
      "Episode 2250 | High tile: 512 | Steps: 529 | Epsilon: 0.0005\n",
      "Episode 2300 | High tile: 512 | Steps: 451 | Epsilon: 0.0005\n",
      "Episode 2350 | High tile: 512 | Steps: 531 | Epsilon: 0.0005\n",
      "Episode 2400 | High tile: 256 | Steps: 237 | Epsilon: 0.0005\n",
      "Episode 2450 | High tile: 512 | Steps: 558 | Epsilon: 0.0005\n",
      "Episode 2500 | High tile: 128 | Steps: 127 | Epsilon: 0.0005\n",
      "Episode 2550 | High tile: 128 | Steps: 224 | Epsilon: 0.0005\n",
      "Episode 2600 | High tile: 512 | Steps: 318 | Epsilon: 0.0005\n",
      "Episode 2650 | High tile: 512 | Steps: 542 | Epsilon: 0.0005\n",
      "Episode 2700 | High tile: 128 | Steps: 220 | Epsilon: 0.0005\n",
      "Episode 2750 | High tile: 128 | Steps: 171 | Epsilon: 0.0005\n",
      "Episode 2800 | High tile: 128 | Steps: 183 | Epsilon: 0.0005\n",
      "Episode 2850 | High tile: 512 | Steps: 587 | Epsilon: 0.0005\n",
      "Episode 2900 | High tile: 512 | Steps: 531 | Epsilon: 0.0005\n",
      "Episode 2950 | High tile: 512 | Steps: 615 | Epsilon: 0.0005\n",
      "Episode 3000 | High tile: 256 | Steps: 313 | Epsilon: 0.0005\n",
      "Episode 3050 | High tile: 128 | Steps: 241 | Epsilon: 0.0005\n",
      "Episode 3100 | High tile: 256 | Steps: 265 | Epsilon: 0.0005\n",
      "Episode 3150 | High tile: 512 | Steps: 489 | Epsilon: 0.0005\n",
      "Episode 3200 | High tile: 512 | Steps: 652 | Epsilon: 0.0005\n",
      "Episode 3250 | High tile: 128 | Steps: 184 | Epsilon: 0.0005\n",
      "Episode 3300 | High tile: 512 | Steps: 432 | Epsilon: 0.0005\n",
      "Episode 3350 | High tile: 128 | Steps: 184 | Epsilon: 0.0005\n",
      "Episode 3400 | High tile: 512 | Steps: 507 | Epsilon: 0.0005\n",
      "Episode 3450 | High tile: 128 | Steps: 131 | Epsilon: 0.0005\n",
      "Episode 3500 | High tile: 256 | Steps: 339 | Epsilon: 0.0005\n",
      "Episode 3550 | High tile: 512 | Steps: 355 | Epsilon: 0.0005\n",
      "Episode 3600 | High tile: 64 | Steps: 95 | Epsilon: 0.0005\n",
      "Episode 3650 | High tile: 128 | Steps: 146 | Epsilon: 0.0005\n",
      "Episode 3700 | High tile: 256 | Steps: 264 | Epsilon: 0.0005\n",
      "Episode 3750 | High tile: 256 | Steps: 344 | Epsilon: 0.0005\n",
      "Episode 3800 | High tile: 512 | Steps: 338 | Epsilon: 0.0005\n",
      "Episode 3850 | High tile: 128 | Steps: 189 | Epsilon: 0.0005\n",
      "Episode 3900 | High tile: 512 | Steps: 494 | Epsilon: 0.0005\n",
      "Episode 3950 | High tile: 512 | Steps: 531 | Epsilon: 0.0005\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "# Main training loop\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    env = gym.make(\"gymnasium_2048/TwentyFortyEight-v0\")\n",
    "\n",
    "    main_net = DQN_CNN().to(device)\n",
    "    target_net = DQN_CNN().to(device)\n",
    "    target_net.load_state_dict(main_net.state_dict())\n",
    "    optimizer = optim.Adam(main_net.parameters(), lr=1e-4)\n",
    "    buffer = PrioritizedReplayBuffer(10000)\n",
    "\n",
    "    batch_size = 128\n",
    "    gamma = 0.99\n",
    "    epsilon = 1.0\n",
    "    epsilon_decay = 0.992\n",
    "    epsilon_min = 0.0005\n",
    "    target_update_freq = 20\n",
    "    num_episodes = 4000\n",
    "    total_steps = 0\n",
    "\n",
    "    with open('run.csv', 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"episode\", \"high_tile\", \"steps\"])\n",
    "\n",
    "    for episode in range(num_episodes):\n",
    "        state, info = env.reset()\n",
    "        total_reward = 0.0\n",
    "        high_tile = 0\n",
    "        done = False\n",
    "        steps = 0\n",
    "\n",
    "        while not done:\n",
    "            if random.random() < epsilon:\n",
    "                actions = [0, 1, 3]\n",
    "                arr = np.array(actions)\n",
    "                np.random.shuffle(arr)\n",
    "                np.append(arr, 2)\n",
    "                for action in actions:\n",
    "                    next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "                    if not np.array_equal(state, next_state):\n",
    "                        break\n",
    "            else:\n",
    "                state_tensor = torch.tensor(np.array([preprocess(state)]), dtype=torch.float32).to(device)\n",
    "                with torch.no_grad():\n",
    "                    q_vals = main_net(state_tensor).squeeze(0)\n",
    "\n",
    "                    actions = torch.argsort(q_vals, descending=True).tolist()\n",
    "                    for action in actions:\n",
    "                        if action == 2:\n",
    "                            continue\n",
    "                        next_state, reward, terminated, truncated, _ = env.step(action) # 1 is right, 0 is up, 3 is left, 2 is down\n",
    "                        if not np.array_equal(state, next_state):\n",
    "                            break\n",
    "                    else:\n",
    "                        next_state, reward, terminated, truncated, _ = env.step(2)\n",
    "                        action = 2 # BUG\n",
    "\n",
    "            steps += 1\n",
    "            shaped_reward = reward_shaping(state) # merge reward\n",
    "            done = terminated or truncated\n",
    "\n",
    "            with torch.no_grad():\n",
    "                s_tensor = torch.tensor(np.array([preprocess(state)]), dtype=torch.float32).to(device)\n",
    "                ns_tensor = torch.tensor(np.array([preprocess(next_state)]), dtype=torch.float32).to(device)\n",
    "\n",
    "                q_sa = main_net(s_tensor)[0, action]\n",
    "                next_action = main_net(ns_tensor).argmax().item()\n",
    "                q_next = target_net(ns_tensor)[0, next_action]\n",
    "\n",
    "                target = shaped_reward + gamma * q_next * (0.0 if done else 1.0)\n",
    "                td_error = target\n",
    "\n",
    "            buffer.add((state, action, shaped_reward, next_state, done), td_error)\n",
    "\n",
    "            state = next_state\n",
    "            total_reward += float(reward)\n",
    "\n",
    "            if len(buffer.buffer) >= batch_size:\n",
    "                samples, weights, indices = buffer.sample(batch_size)\n",
    "                batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones = zip(*samples)\n",
    "\n",
    "                batch_states = torch.tensor(np.array([preprocess(s) for s in batch_states]), dtype=torch.float32).to(device)\n",
    "                batch_actions = torch.tensor(batch_actions).to(device)\n",
    "                batch_rewards = torch.tensor(batch_rewards, dtype=torch.float32).to(device)\n",
    "                batch_next_states = torch.tensor(np.array([preprocess(s) for s in batch_next_states]), dtype=torch.float32).to(device)\n",
    "                batch_dones = torch.tensor(batch_dones, dtype=torch.float32).to(device)\n",
    "                weights = weights.to(device)\n",
    "\n",
    "                q_values = main_net(batch_states).gather(1, batch_actions.unsqueeze(1)).squeeze(1)\n",
    "\n",
    "                # Double DQN: action from main_net, value from target_net\n",
    "                next_actions = main_net(batch_next_states).argmax(1, keepdim=True)\n",
    "                next_q_values = target_net(batch_next_states).gather(1, next_actions).squeeze(1)\n",
    "\n",
    "                target_q_values = batch_rewards + gamma * next_q_values * (1 - batch_dones)\n",
    "\n",
    "                loss = ((q_values - target_q_values.detach()) ** 2 * weights).mean()\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                td_errors = torch.abs(q_values - target_q_values.detach())\n",
    "                buffer.update_priorities(indices, td_errors)\n",
    "\n",
    "            total_steps += 1\n",
    "            if total_steps % target_update_freq == 0:\n",
    "                target_net.load_state_dict(main_net.state_dict())\n",
    "\n",
    "\n",
    "        epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
    "\n",
    "        with open('run.csv', 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([episode, find_high_tile(state), steps])\n",
    "\n",
    "        if episode % 50 == 0:\n",
    "            print(f\"Episode {episode:03d} | High tile: {find_high_tile(state)} | Steps: {steps} | Epsilon: {epsilon:.4f}\")\n",
    "\n",
    "        if episode == 2000:\n",
    "            torch.save(main_net.state_dict(), \"dqn_2048_2000.pth\")\n",
    "        if episode == 2500:\n",
    "            torch.save(main_net.state_dict(), \"dqn_2048_2500.pth\")\n",
    "        if episode == 3000:\n",
    "            torch.save(main_net.state_dict(), \"dqn_2048_3000.pth\")\n",
    "        if episode == 3500:\n",
    "            torch.save(main_net.state_dict(), \"dqn_2048_3500.pth\")\n",
    "\n",
    "    env.close()\n",
    "    torch.save(main_net.state_dict(), \"dqn_2048.pth\")\n",
    "    print(\"Model saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2048",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
